# FEDA Project: A Forest-guided Estimation of Distribution Algorithm for Optimization

This project focuses on the implementation and application of a **Forest-guided Estimation of Distribution Algorithm (FEDA)**, specifically an RF-MIMIC variant. This algorithm uses a Random Forest classifier to model the distribution of elite solutions and guide the sampling of new candidate solutions for complex optimization problems.

For comparative purposes, an implementation of the **MIMIC (Mutual Information Maximizing Input Clustering)** algorithm is also included.

Both algorithms are demonstrated by applying them to solve the NK-Landscape problem, a tunable rugged fitness landscape commonly used for benchmarking optimization algorithms.

## Core Algorithm: RF-MIMIC (Forest-guided EDA)

The primary algorithm in this project is the RF-MIMIC:
   - **Core Idea**: It maintains a population of candidate solutions. In each iteration, it selects elite individuals (the best-performing solutions) and trains a Random Forest (RF) classifier. This RF learns to distinguish the characteristics of these elite solutions from the non-elite ones. New, potentially better, solutions are then generated by probabilistically traversing the trees of the trained RF, effectively mimicking the properties of the high-performing individuals.
   - **Key Features**:
     - Leverages scikit-learn's `RandomForestClassifier` as its learning engine.
     - Employs a biased tree traversal mechanism, guided by elite sample distributions within the RF, for generating new candidate solutions.
     - Includes robust fallbacks for situations such as insufficient training data for the Random Forest.
   - **File**: `feda_algorithm/optimizer.py` (Class: `RF_MIMIC`)

## Comparative Algorithm: MIMIC_O2

To provide a benchmark and explore alternative EDA approaches, a version of the MIMIC algorithm is also implemented:
   - **Core Idea**: Selects elite individuals and computes pairwise mutual information between variables (genes) within this elite set. It then constructs a dependency tree (approximating a Maximum Spanning Tree based on mutual information) representing the relationships between variables. New solutions are sampled sequentially based on this tree structure, using conditional probabilities derived from the elite samples.
   - **Key Features**:
     - Builds a probabilistic model based on first and second-order statistics (marginal and pairwise).
     - Uses a tree structure to capture dependencies.
     - Includes a diversity injection mechanism if the population converges prematurely.
   - **File**: `feda_algorithm/optimizer.py` (Class: `MIMIC_O2`)

## Project Structure

feda-project/
├── .gitignore
├── README.md
├── requirements.txt
├── examples/
│   └── run_feda_nk.py        # Main script to run experiments and compare algorithms
├── feda_algorithm/
│   ├── __init__.py
│   └── optimizer.py          # Contains RF_MIMIC and MIMIC_O2 classes
├── problem_definitions/
│   ├── __init__.py
│   └── nk_landscape.py       # Defines the NK-Landscape problem
└── utils/
    ├── __init__.py
    └── debugging.py          # Utility for debug printing
## Setup Instructions

### Prerequisites
* Python (e.g., Python 3.8+ recommended)
* `pip` (Python package installer)

### Installation
1.  **Clone the repository (if you haven't already):**
    ```bash
    git clone [https://github.com/tortawan/feda-project.git](https://github.com/tortawan/feda-project.git)
    cd feda-project
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    ```
    Activate the virtual environment:
    * On Windows:
        ```bash
        .\venv\Scripts\activate
        ```
    * On macOS and Linux:
        ```bash
        source venv/bin/activate
        ```

3.  **Install dependencies:**
    Navigate to the project root directory (where `requirements.txt` is located) and run:
    ```bash
    pip install -r requirements.txt
    ```
    This will install `numpy`, `scikit-learn`, `matplotlib`, and `pytest` as specified in the `requirements.txt` file.

## How to Run the Examples

The primary script for running experiments is `examples/run_feda_nk.py`.

1.  **Navigate to the `examples` directory (or run from the root):**
    ```bash
    cd examples
    python run_feda_nk.py
    ```
    Or from the project root:
    ```bash
    python examples/run_feda_nk.py
    ```

2.  **Understanding `run_feda_nk.py`:**
    * This script is configured to run both the primary `RF_MIMIC` algorithm and the comparative `MIMIC_O2` algorithm sequentially on the same NK-Landscape problem instance.
    * You can modify problem parameters (N_genes, K_interactions, landscape_seed) and algorithm parameters (population_size, max_iterations, elite_ratio, etc.) directly within this script.
    * The script will print the configuration for each algorithm, its progress (if `DEBUG_MODE` is on), and a final summary of its performance (best fitness, total time).

### Enabling Debug Mode

To see detailed iteration-by-iteration logs from the optimizers (including average population fitness):
1.  Open the file `utils/debugging.py`.
2.  Change the line `DEBUG_MODE = False` to `DEBUG_MODE = True`.
3.  Save the file and re-run `examples/run_feda_nk.py`.

The debug output will show the initial best and average fitness, fitness statistics at regular iteration intervals, and final fitness values for each algorithm run.

## Interpreting Results

When you run `examples/run_feda_nk.py`, the script will output:
* **Problem Definition**: Details of the NK-Landscape being solved (N, K, seed).
* **Algorithm Configuration**: Parameters used for each optimizer.
* **Optimization Progress (if `DEBUG_MODE` is True)**:
    * `Initial Best Fitness`: The best fitness found in the initial random population.
    * `Initial Avg Fitness`: The average fitness of the initial random population.
    * `Iteration X/Y: ...`: For every 10th iteration (and the last one):
        * `Iter Pop Best`: The best fitness found in the population *generated in that specific iteration*.
        * `Iter Pop Avg`: The average fitness of the population *generated in that specific iteration*.
        * `Overall Best`: The best fitness found by the algorithm *up to that point across all iterations*.
        * `Time`: Time taken for that iteration.
* **Optimization Complete Summary (for each algorithm)**:
    * `Total execution time`: Wall-clock time for the algorithm's run.
    * `Best fitness achieved`: The highest fitness value found by the algorithm.
    * `Best solution found (first 10 genes)`: The first 10 genes of the best solution vector (since the full vector can be long).
* **Overall Comparison Summary**: A final brief comparison of the best fitness and total time for each algorithm tested.

**Key metrics to evaluate the FEDA (RF-MIMIC) algorithm and compare:**
* **Best Fitness Achieved**: Higher is generally better. This indicates the quality of the best solution found by RF-MIMIC.
* **Total Execution Time**: Lower is generally better, indicating efficiency.
* **Fitness History (from debug logs or future plotting)**: How quickly does the "Overall Best" fitness improve for RF-MIMIC? Does it plateau early? A steeper, higher curve is desirable.
* **Average Population Fitness (from debug logs)**: A generally increasing average fitness suggests RF-MIMIC is effectively guiding the entire population towards better regions.

For robust conclusions, it's recommended to run experiments multiple times with different random seeds for the optimizer runs and analyze the statistical properties of the results.
