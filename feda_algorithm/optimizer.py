# feda_project/feda_algorithm/optimizer.py
"""
Implements the core Forest-guided Estimation of Distributions Algorithm (FEDA).

This module contains the RF_MIMIC class, which uses a Random Forest classifier
to guide the sampling of new candidate solutions in an Estimation of
Distribution Algorithm framework.
"""

import numpy as np
import time
import random
from sklearn.ensemble import RandomForestClassifier
from ..utils.debugging import print_debug # Assuming utils is a sibling directory

class RF_MIMIC:
    """
    Implements the Forest-guided Estimation of Distributions Algorithm (FEDA).

    This algorithm uses a Random Forest (RF) classifier to model the distribution
    of elite solutions in a population. New candidate solutions are generated by
    probabilistically traversing the trees of the trained RF, aiming to mimic
    the characteristics of high-performing individuals.

    Attributes:
        problem: An object representing the optimization problem. It must have
                 a 'num_genes' (or 'num_items') attribute and a callable
                 'fitness(individual)' method.
        num_genes (int): The number of genes (variables) in an individual solution.
        fitness_fn (callable): The fitness function to evaluate individuals.
        pop_size (int): The size of the population.
        max_iterations (int): The maximum number of generations.
        elite_ratio (float): The fraction (or count if >=1.0) of the population
                             to be selected as elite.
        rf_params (dict): Parameters for the scikit-learn RandomForestClassifier.
        branch_alpha (float): Smoothing parameter for probabilistic branch selection
                              during tree traversal.
        random_seed (int, optional): Seed for reproducibility.
        population (np.ndarray): The current population of solutions.
        fitnesses (np.ndarray): Fitness values for the current population.
        best_solution (np.ndarray): The best solution found so far.
        best_fitness (float): The fitness of the best_solution.
        fitness_history (list[float]): A list tracking the best fitness per iteration.
        timing_info (dict): A dictionary storing timing information for the run.
        rf_model_for_inspection (RandomForestClassifier): The last trained RF model,
                                                         available for inspection.
    """
    def __init__(self, problem, population_size: int = 100,
                 max_iterations: int = 100, elite_ratio: float = 0.2,
                 rf_params: dict = None, branch_alpha: float = 0.1):
        """Initializes the RF_MIMIC (FEDA) optimizer.

        Args:
            problem: The optimization problem instance. Must have 'num_genes'
                     (or 'num_items') and a 'fitness' method.
            population_size (int): Number of individuals in the population.
            max_iterations (int): Maximum number of algorithm iterations.
            elite_ratio (float): Proportion or count of elite individuals.
                                 If < 1.0, it's a ratio; otherwise, it's a count.
            rf_params (dict, optional): Dictionary of parameters for the
                                        RandomForestClassifier. Defaults to None,
                                        which uses internal defaults.
            branch_alpha (float): Smoothing factor for probabilistic tree traversal.
                                  A small positive value to prevent zero probabilities.

        Raises:
            ValueError: If 'problem' does not have 'num_genes'/'num_items' or 'fitness'.
        """
        if hasattr(problem, 'num_genes'):
            self.num_genes = problem.num_genes
        elif hasattr(problem, 'num_items'):
            self.num_genes = problem.num_items # Use num_items as num_genes
        else:
            raise ValueError("The 'problem' object must have a 'num_genes' or 'num_items' attribute.")

        if hasattr(problem, 'fitness') and callable(problem.fitness):
            self.fitness_fn = problem.fitness
        else:
            raise ValueError("The 'problem' object must have a callable 'fitness' method.")

        self.pop_size = population_size
        self.max_iterations = max_iterations
        self.elite_ratio = elite_ratio
        self.rf_params = rf_params if rf_params is not None else {}

        # Default RF parameters (can be overridden by rf_params)
        self.rf_params.setdefault('n_estimators', 10)
        self.rf_params.setdefault('min_samples_leaf', 1)
        # 'random_state' will be set in run() for reproducibility

        self.branch_alpha = branch_alpha
        self.random_seed = None # Will be set in run()

        # Algorithm state variables
        self.population = None
        self.fitnesses = None
        self.best_solution = None
        self.best_fitness = -np.inf
        self.fitness_history = []
        self.timing_info = {'total_time': 0.0, 'iteration_times':[]}
        self.rf_model_for_inspection = None # To store the last RF model

    def _initialize_population(self) -> np.ndarray:
        """Initializes the population with random binary strings.

        The size of the population is determined by `self.pop_size`, and
        the length of each individual (number of genes) is `self.num_genes`.
        Handles the case where `self.num_genes` is 0.

        Returns:
            np.ndarray: A 2D NumPy array representing the initial population,
                        where each row is an individual. Returns an empty array
                        shaped (pop_size, 0) if num_genes is 0.
        """
        if self.num_genes == 0:
            return np.array().reshape(self.pop_size, 0)
        return np.random.randint(0, 2, size=(self.pop_size, self.num_genes), dtype=int)

    def _evaluate_population(self, population: np.ndarray) -> np.ndarray:
        """Evaluates the fitness of each individual in the given population.

        Args:
            population (np.ndarray): A 2D NumPy array where each row is an
                                     individual solution.

        Returns:
            np.ndarray: A 1D NumPy array containing the fitness value for
                        each individual in the input population. Returns an
                        empty array if the input population is empty.
        """
        if population.shape == 0: # Empty population
            return np.array()
        # For 0-gene problems, population might be (pop_size, 0)
        # The fitness function should handle individual.shape == (0,)
        return np.array([self.fitness_fn(ind) for ind in population])

    def _select_elite(self, population: np.ndarray, fitnesses: np.ndarray) -> tuple:
        """Selects elite and non-elite individuals from the population.

        Selection is based on fitness values. The number of elites is determined
        by `self.elite_ratio`.

        Args:
            population (np.ndarray): The current population of solutions.
            fitnesses (np.ndarray): The fitness values corresponding to the population.

        Returns:
            tuple: A tuple containing:
                - elite_pop (np.ndarray): Array of elite individuals.
                - elite_fitnesses (np.ndarray): Fitnesses of elite individuals.
                - nonelite_pop (np.ndarray): Array of non-elite individuals.
                - nonelite_fitnesses (np.ndarray): Fitnesses of non-elite individuals.
        """
        pop_size_current = population.shape
        if pop_size_current == 0:
            return (np.array().reshape(0, self.num_genes), np.array(),
                    np.array().reshape(0, self.num_genes), np.array())

        if self.elite_ratio < 1.0: # Elite ratio is a fraction
            elite_count = int(np.floor(pop_size_current * self.elite_ratio))
        else: # Elite ratio is an absolute count
            elite_count = int(self.elite_ratio)

        # Ensure elite_count is valid
        elite_count = max(1 if pop_size_current > 0 else 0, elite_count)
        elite_count = min(elite_count, pop_size_current)

        if elite_count == 0 and pop_size_current > 0: # Ensure at least one elite if pop exists
            elite_count = 1
            
        if fitnesses.size == 0 and pop_size_current > 0 :
            print_debug("RF_MIMIC Warn: Fitnesses empty in _select_elite despite population. Re-evaluating.")
            fitnesses = self._evaluate_population(population)
            if fitnesses.size == 0: # Still empty, indicates a deeper issue or 0 pop
                return (np.array().reshape(0,self.num_genes), np.array(),
                        np.array().reshape(0,self.num_genes), np.array())

        sorted_idx = np.argsort(fitnesses)[::-1] # Sort descending by fitness
        elite_indices = sorted_idx[:elite_count]
        nonelite_indices = sorted_idx[elite_count:]

        elite_pop = population[elite_indices]
        elite_fitnesses = fitnesses[elite_indices]
        nonelite_pop = population[nonelite_indices]
        nonelite_fitnesses = fitnesses[nonelite_indices]

        return elite_pop, elite_fitnesses, nonelite_pop, nonelite_fitnesses

    def _train_random_forest(self, elite_population: np.ndarray,
                             nonelite_population: np.ndarray) -> RandomForestClassifier:
        """Trains a Random Forest classifier to distinguish elites from non-elites.

        Args:
            elite_population (np.ndarray): Individuals classified as elite (Class 1).
            nonelite_population (np.ndarray): Individuals classified as non-elite (Class 0).

        Returns:
            RandomForestClassifier: The trained scikit-learn RandomForestClassifier.
                                    Returns an unfitted model if training data is
                                    insufficient or an error occurs.
        """
        current_rf_params = self.rf_params.copy()
        current_rf_params['random_state'] = self.random_seed # For reproducibility

        # Adjust min_samples_leaf if it's too large for the elite set
        if elite_population.shape > 0:
            max_min_leaf = max(1, elite_population.shape // 2 if elite_population.shape > 1 else 1)
            if current_rf_params.get('min_samples_leaf', 1) > max_min_leaf:
                current_rf_params['min_samples_leaf'] = max_min_leaf
        
        rf_model_unfitted = RandomForestClassifier(**current_rf_params)

        if elite_population.shape == 0 or nonelite_population.shape == 0:
            print_debug(f"RF_MIMIC Warning: RF training with insufficient distinct classes. Elites: {elite_population.shape}, Non-elites: {nonelite_population.shape}")
            return rf_model_unfitted # Return unfitted model

        X_train = np.vstack((elite_population, nonelite_population))
        y_train = np.concatenate((
            np.ones(elite_population.shape, dtype=int),    # Elites are class 1
            np.zeros(nonelite_population.shape, dtype=int) # Non-elites are class 0
        ))

        if len(np.unique(y_train)) < 2:
            print_debug(f"RF_MIMIC Warning: Training RF with only one class. Unique labels: {np.unique(y_train)}")
            return rf_model_unfitted
        
        if X_train.shape == 0:
            print_debug("RF_MIMIC Warning: No data to train Random Forest (X_train is empty).")
            return rf_model_unfitted

        try:
            rf_model_unfitted.fit(X_train, y_train)
            self.rf_model_for_inspection = rf_model_unfitted # Store for potential inspection
        except ValueError as e:
            print_debug(f"RF_MIMIC Warning: RandomForestClassifier fitting error: {e}. Returning unfitted model.")
            return RandomForestClassifier(**current_rf_params) # Return a new unfitted one
        return rf_model_unfitted

    def _sample_new_population(self, rf_model: RandomForestClassifier,
                               elite_population: np.ndarray) -> np.ndarray:
        """Generates a new population by sampling from the trained Random Forest.

        This method uses a mixture-of-trees approach with biased traversal.
        Each new individual is generated by:
        1. Selecting a tree from the forest.
        2. Probabilistically traversing the tree from root to leaf, where branching
           decisions are biased by the proportion of elite samples in child nodes.
        3. Completing unspecified features at the leaf node based on the marginal
           distribution of those features in elite samples that reached that leaf
           (or all elites as a fallback).

        Args:
            rf_model (RandomForestClassifier): The trained Random Forest model.
            elite_population (np.ndarray): The current set of elite individuals,
                                           used for completing unspecified features.

        Returns:
            np.ndarray: A 2D NumPy array representing the new population.
                        Handles fallbacks if RF model is not properly trained or
                        if population generation issues arise.
        """
        new_population_list =[]

        if self.pop_size == 0: return np.array().reshape(0, self.num_genes)
        if self.num_genes == 0: return np.array().reshape(self.pop_size, 0)

        if not hasattr(rf_model, 'estimators_') or not rf_model.estimators_:
            print_debug("RF_MIMIC Warning: RF model not trained or has no trees. Falling back.")
            if elite_population.shape > 0 and self.pop_size > 0:
                return self._sample_new_population_from_elites_only(elite_population, target_size=self.pop_size)
            return self._initialize_population()

        trees = rf_model.estimators_
        n_trees = len(trees)
        if n_trees == 0:
            print_debug("RF_MIMIC Warning: RF model has no trees (estimators_ is empty). Falling back.")
            if elite_population.shape > 0 and self.pop_size > 0:
                return self._sample_new_population_from_elites_only(elite_population, target_size=self.pop_size)
            return self._initialize_population()

        samples_per_tree = [self.pop_size // n_trees] * n_trees
        for i in range(self.pop_size % n_trees): samples_per_tree[i] += 1

        elite_leaf_indices_per_tree = []
        if elite_population.shape > 0:
            for tree in trees:
                try:
                    if hasattr(tree, 'tree_') and tree.tree_ is not None:
                        elite_leaf_idx = tree.apply(elite_population)
                        elite_leaf_indices_per_tree.append(elite_leaf_idx)
                    else:
                        elite_leaf_indices_per_tree.append(np.array([], dtype=int))
                except Exception:
                    elite_leaf_indices_per_tree.append(np.array([], dtype=int))
        else:
            for _ in trees: elite_leaf_indices_per_tree.append(np.array([], dtype=int))

        for t_index, tree in enumerate(trees):
            num_samples_from_this_tree = samples_per_tree[t_index]
            if num_samples_from_this_tree == 0: continue

            try:
                tree_struct = tree.tree_
                if tree_struct is None:
                    print_debug(f"RF_MIMIC Warning: Tree {t_index} has no tree_struct (None). Skipping.")
                    continue
            except AttributeError:
                print_debug(f"RF_MIMIC Warning: Tree {t_index} does not have 'tree_' attribute. Skipping.")
                continue

            leaf_to_elite_indices = {}
            if elite_population.shape > 0 and t_index < len(elite_leaf_indices_per_tree) and elite_leaf_indices_per_tree[t_index].size > 0:
                leaf_idx_for_elites_this_tree = elite_leaf_indices_per_tree[t_index]
                for elite_idx, leaf_node_id in enumerate(leaf_idx_for_elites_this_tree):
                    leaf_to_elite_indices.setdefault(leaf_node_id,).append(elite_idx)

            for _ in range(num_samples_from_this_tree):
                node = 0  # Start from root
                path_decisions = {} # {feature_index: value}

                while tree_struct.feature[node]!= -2: # -2 is leaf marker
                    feature_index = tree_struct.feature[node]
                    left_child = tree_struct.children_left[node]
                    right_child = tree_struct.children_right[node]

                    model_classes = getattr(rf_model, 'classes_', np.array())
                    class_index1 = -1
                    if 1 in model_classes: class_index1 = list(model_classes).index(1)

                    left_count1, right_count1 = 0.0, 0.0
                    if class_index1!= -1:
                        if left_child!= -1 and tree_struct.value[left_child].ndim >=2 and \
                           class_index1 < tree_struct.value[left_child].shape:
                            left_count1 = tree_struct.value[left_child][0, class_index1]
                        if right_child!= -1 and tree_struct.value[right_child].ndim >=2 and \
                           class_index1 < tree_struct.value[right_child].shape:
                            right_count1 = tree_struct.value[right_child][0, class_index1]
                    
                    total1 = left_count1 + right_count1
                    denominator = total1 + 2 * self.branch_alpha # Smoothing
                    p_left = (left_count1 + self.branch_alpha) / denominator if denominator > 1e-9 else 0.5

                    if random.random() < p_left:
                        path_decisions[feature_index] = 0 # Assuming binary features and split convention
                        node = left_child
                    else:
                        path_decisions[feature_index] = 1
                        node = right_child
                    
                    if node == -1: # Should not happen
                        print_debug("RF_MIMIC Warning: Traversed to a non-existent child node (-1).")
                        break
                
                individual = np.full(self.num_genes, -1, dtype=int) # -1 for unassigned
                for feat_idx, feat_val in path_decisions.items():
                    if 0 <= feat_idx < self.num_genes:
                        individual[feat_idx] = feat_val

                elites_in_this_leaf_indices = leaf_to_elite_indices.get(node,)
                elites_in_this_leaf_samples = elite_population[elites_in_this_leaf_indices] if len(elites_in_this_leaf_indices) > 0 and elite_population.shape > 0 else np.array()

                for j in range(self.num_genes):
                    if individual[j] == -1: # Gene not set by tree path
                        if elites_in_this_leaf_samples.shape > 0:
                            prob_one = np.mean(elites_in_this_leaf_samples[:, j])
                        elif elite_population.shape > 0: # Fallback to all elites
                            prob_one = np.mean(elite_population[:,j])
                        else: # Fallback to random
                            prob_one = 0.5
                        individual[j] = 1 if random.random() < prob_one else 0
                new_population_list.append(individual)

        if not new_population_list and self.pop_size > 0:
            print_debug("RF_MIMIC Warning: New population list empty after RF sampling. Falling back.")
            if elite_population.shape > 0:
                return self._sample_new_population_from_elites_only(elite_population, target_size=self.pop_size)
            return self._initialize_population()

        final_population_array = np.array(new_population_list, dtype=int)

        # Ensure population is of the correct size
        if final_population_array.shape < self.pop_size and self.pop_size > 0:
            num_needed = self.pop_size - final_population_array.shape
            print_debug(f"RF_MIMIC: Population short by {num_needed} after RF sampling. Filling...")
            fill_samples = np.array()
            if elite_population.shape > 0:
                fill_samples = self._sample_new_population_from_elites_only(elite_population, target_size=num_needed)
            else:
                if self.num_genes > 0:
                    fill_samples = np.random.randint(0,2,size=(num_needed, self.num_genes))
                else:
                    fill_samples = np.array().reshape(num_needed, 0)
            
            if final_population_array.shape == 0: final_population_array = fill_samples
            elif fill_samples.shape > 0: final_population_array = np.vstack((final_population_array, fill_samples))

        if final_population_array.shape > self.pop_size:
            final_population_array = final_population_array[:self.pop_size]
        
        if self.num_genes == 0 and self.pop_size > 0:
            return np.array().reshape(self.pop_size, 0)
        if self.pop_size == 0:
            return np.array().reshape(0, self.num_genes)
            
        return final_population_array

    def _sample_new_population_from_elites_only(self, elite_population: np.ndarray, target_size: int) -> np.ndarray:
        """Generates new individuals based solely on the elite population's gene frequencies.

        This is a fallback sampling method used when RF-based sampling is not
        possible (e.g., RF training failed or produced no trees). Each gene in a
        new individual is set to 1 with a probability equal to the mean of that
        gene's value across all elite individuals.

        Args:
            elite_population (np.ndarray): The current set of elite individuals.
            target_size (int): The number of new individuals to generate.

        Returns:
            np.ndarray: A 2D NumPy array representing the new individuals.
                        If no elites exist, generates random individuals.
        """
        if target_size == 0: return np.array().reshape(0, self.num_genes)
        if self.num_genes == 0: return np.array().reshape(target_size, 0)

        new_population = []
        num_elites = elite_population.shape

        if num_elites == 0: # No elites, generate randomly
            return np.random.randint(0, 2, size=(target_size, self.num_genes), dtype=int)

        for _ in range(target_size):
            individual = np.zeros(self.num_genes, dtype=int)
            for j in range(self.num_genes):
                prob_one = np.mean(elite_population[:, j])
                individual[j] = 1 if random.random() < prob_one else 0
            new_population.append(individual)
        return np.array(new_population, dtype=int)

    def run(self, random_seed: int = None):
        """Runs the FEDA optimization process.

        Args:
            random_seed (int, optional): Seed for random number generators
                                         (NumPy, Python's random, and scikit-learn's RF)
                                         to ensure reproducibility. If None, a seed
                                         will be generated or an existing one reused.

        Returns:
            tuple: A tuple containing:
                - best_solution (np.ndarray): The best solution found.
                - best_fitness (float): The fitness of the best solution.
                - fitness_history (list[float]): History of best fitness per iteration.
                - timing_info (dict): Execution times for iterations and total.
                                      Returns (None, -np.inf,, timing_info) if
                                      pop_size is 0 and num_genes > 0.
                                      Returns (empty_array, fitness,, timing_info) if
                                      pop_size is 0 and num_genes is 0.
        """
        if random_seed is not None:
            self.random_seed = random_seed
            np.random.seed(self.random_seed)
            random.seed(self.random_seed)
        elif self.random_seed is None: # If no seed provided and none set yet
            self.random_seed = np.random.randint(0, 1_000_000)
            np.random.seed(self.random_seed)
            random.seed(self.random_seed)
        # If self.random_seed was already set, it will be used.

        self.rf_params['random_state'] = self.random_seed # Ensure RF uses this seed

        overall_start_time = time.time()
        self.fitness_history = []
        self.timing_info = {'total_time': 0.0, 'iteration_times':[]}
        self.best_solution = None # Reset for multiple runs
        self.best_fitness = -np.inf # Reset for multiple runs

        if self.pop_size == 0:
            print_debug("RF_MIMIC: Population size is 0. Returning.")
            self.timing_info['total_time'] = time.time() - overall_start_time
            if self.num_genes == 0:
                empty_sol_fitness = self.fitness_fn(np.array().reshape(0,))
                return np.array().reshape(0,), empty_sol_fitness,[], self.timing_info
            else:
                return None, -np.inf,[], self.timing_info

        init_time_start = time.time()
        self.population = self._initialize_population()
        
        if self.population.shape > 0:
            self.fitnesses = self._evaluate_population(self.population)
        else: # Population is empty (e.g. pop_size=0, or num_genes=0 led to (0,0) shape)
            self.fitnesses = np.array()

        if self.fitnesses.size > 0:
            current_best_idx = np.argmax(self.fitnesses)
            self.best_solution = self.population[current_best_idx].copy()
            self.best_fitness = self.fitnesses[current_best_idx]
        else: # No fitnesses
            if self.num_genes == 0:
                self.best_solution = np.array().reshape(0,)
                self.best_fitness = self.fitness_fn(self.best_solution)
            # else: best_fitness remains -np.inf, best_solution None

        self.fitness_history.append(self.best_fitness)
        self.timing_info['iteration_times'].append(time.time() - init_time_start)
        print_debug(f" Initial Best Fitness: {self.best_fitness:.4f}")

        for iteration in range(self.max_iterations):
            iter_start_time = time.time()

            elite_pop, _, nonelite_pop, _ = \
                self._select_elite(self.population, self.fitnesses)
            
            action_taken = "initial_selection_done"

            if elite_pop.shape == 0 and self.pop_size > 0:
                print_debug(f"FEDA Iter {iteration + 1}: No elite samples. Re-initializing.")
                self.population = self._initialize_population()
                action_taken = "reinit_due_to_no_elites"
            elif nonelite_pop.shape == 0 and elite_pop.shape == self.pop_size and self.pop_size > 0:
                print_debug(f"FEDA Iter {iteration + 1}: All samples are elite. Sampling from elites.")
                self.population = self._sample_new_population_from_elites_only(elite_pop, target_size=self.pop_size)
                action_taken = "sample_from_all_elites"
            elif self.pop_size > 0: # Standard case
                rf_model = self._train_random_forest(elite_pop, nonelite_pop)
                if hasattr(rf_model, 'estimators_') and rf_model.estimators_ and len(rf_model.estimators_) > 0:
                    self.population = self._sample_new_population(rf_model, elite_pop)
                    action_taken = "sampled_from_trained_rf"
                else:
                    print_debug(f"FEDA Iter {iteration + 1}: RF model not effectively trained. Fallback.")
                    if elite_pop.shape > 0:
                        self.population = self._sample_new_population_from_elites_only(elite_pop, target_size=self.pop_size)
                        action_taken = "rf_train_fail_fallback_elites"
                    else:
                        self.population = self._initialize_population()
                        action_taken = "rf_train_fail_fallback_random"
            
            # Ensure population size is correct
            if self.pop_size > 0 and (self.population.shape!= self.pop_size or \
                                     (self.num_genes == 0 and self.population.shape[1]!=0)):
                print_debug(f"FEDA Iter {iteration + 1}: Pop size {self.population.shape} not {self.pop_size}x{self.num_genes} after {action_taken}. Adjusting.")
                if self.population.shape < self.pop_size:
                    num_needed = self.pop_size - self.population.shape
                    fill_samples = np.array()
                    if elite_pop.shape > 0 :
                        fill_samples = self._sample_new_population_from_elites_only(elite_pop, target_size=num_needed)
                    else:
                        if self.num_genes > 0:
                            fill_samples = np.random.randint(0, 2, size=(num_needed, self.num_genes), dtype=int)
                        else:
                            fill_samples = np.array().reshape(num_needed, 0)
                    
                    if self.population.shape == 0: self.population = fill_samples
                    elif fill_samples.shape > 0: self.population = np.vstack((self.population, fill_samples))
                
                elif self.population.shape > self.pop_size:
                    self.population = self.population[:self.pop_size]
                
                if self.num_genes == 0 and self.population.shape!= (self.pop_size, 0):
                    self.population = np.array().reshape(self.pop_size, 0)

            if self.pop_size > 0 and self.population.shape == 0 and self.num_genes > 0 :
                print_debug(f"FEDA Critical Error: Population empty at iter {iteration + 1}. Reinitializing.")
                self.population = self._initialize_population() # Attempt recovery

            current_iter_best_fitness = -np.inf
            if self.population.shape > 0:
                self.fitnesses = self._evaluate_population(self.population)
                if self.fitnesses.size > 0:
                    current_iter_best_idx = np.argmax(self.fitnesses)
                    current_iter_best_fitness = self.fitnesses[current_iter_best_idx]

                    if current_iter_best_fitness > self.best_fitness:
                        self.best_fitness = current_iter_best_fitness
                        self.best_solution = self.population[current_iter_best_idx].copy()
            elif self.num_genes == 0: # Pop is (pop_size,0), fitness is fixed
                current_iter_best_fitness = self.best_fitness

            self.fitness_history.append(self.best_fitness)
            iter_time_taken = time.time() - iter_start_time
            self.timing_info['iteration_times'].append(iter_time_taken)

            if (iteration + 1) % 10 == 0 or iteration == self.max_iterations - 1:
                print_debug(f" Iteration {iteration + 1}/{self.max_iterations}: "
                              f"Iter Pop Best = {current_iter_best_fitness:.4f}, "
                              f"Overall Best = {self.best_fitness:.4f}, Time: {iter_time_taken:.2f}s")

        self.timing_info['total_time'] = time.time() - overall_start_time
        print_debug(f" Optimization finished. Total time: {self.timing_info['total_time']:.2f}s")
        print_debug(f" Final Best Fitness: {self.best_fitness:.4f}")
        return self.best_solution, self.best_fitness, self.fitness_history, self.timing_info